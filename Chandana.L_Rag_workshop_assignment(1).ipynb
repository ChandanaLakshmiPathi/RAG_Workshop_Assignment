{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb8e690-bae7-41bc-bd2d-6912c66645a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 1: LIBRARIES AND SETUP\n",
    "# ========================================================================\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e05636-1596-4664-ba89-8f36f95917d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 2: LOADING CAREER DOCUMENTS\n",
      "============================================================\n",
      "✅ Loaded 210 career-related documents successfully!\n",
      "📘 Topic explanation: I chose the topic 'Career Guidance & Professional Development' because it helps students and professionals improve job readiness skills like resume writing, interviewing, and workplace success.\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 2: LOAD CAREER DOCUMENTS\n",
    "# ========================================================================\n",
    "# Domain: Career Guidance & Professional Development\n",
    "# PDFs are stored inside ./data/ folder\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 2: LOADING CAREER DOCUMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "DATA_DIR = \"./data(1)\"\n",
    "loader = PyPDFDirectoryLoader(DATA_DIR)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} career-related documents successfully!\")\n",
    "\n",
    "# Example PDFs you can include:\n",
    "# 1. Career_Guide_PSU.pdf\n",
    "# 2. Resume_Writing_Guide_ISU.pdf\n",
    "# 3. Interview_Preparation_Handbook.pdf\n",
    "# 4. Professional_Skills_for_Success.pdf\n",
    "# 5. Career_Development_Toolkit.pdf\n",
    "\n",
    "topic_explanation = \"I chose the topic 'Career Guidance & Professional Development' because it helps students and professionals improve job readiness skills like resume writing, interviewing, and workplace success.\"\n",
    "print(f\"📘 Topic explanation: {topic_explanation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae63ee4-a504-4ab8-87a5-bcbbb05feeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 3: DOCUMENT CHUNKING TEST\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Testing config: Small chunks\n",
      "------------------------------------------------------------\n",
      "Total chunks: 2530\n",
      "Average length: 349 characters\n",
      "\n",
      "------------------------------------------------------------\n",
      "Testing config: Large chunks\n",
      "------------------------------------------------------------\n",
      "Total chunks: 562\n",
      "Average length: 928 characters\n",
      "\n",
      "✅ Recommended: Large chunks (1200/50) — balances readability and context retention.\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 3: CHUNKING CONFIGURATION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 3: DOCUMENT CHUNKING TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "configs = [\n",
    "    {\"name\": \"Small chunks\", \"chunk_size\": 400, \"chunk_overlap\": 200},\n",
    "    {\"name\": \"Large chunks\", \"chunk_size\": 1200, \"chunk_overlap\": 50}\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"Testing config: {cfg['name']}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=cfg[\"chunk_size\"],\n",
    "        chunk_overlap=cfg[\"chunk_overlap\"],\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_documents(documents)\n",
    "    total_chunks = len(chunks)\n",
    "    avg_len = sum(len(c.page_content) for c in chunks) / total_chunks if total_chunks else 0\n",
    "    \n",
    "    print(f\"Total chunks: {total_chunks}\")\n",
    "    print(f\"Average length: {avg_len:.0f} characters\")\n",
    "\n",
    "# Recommendation for career PDFs (structured text):\n",
    "print(\"\\n✅ Recommended: Large chunks (1200/50) — balances readability and context retention.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6c0223-6e85-4602-a166-63f39c38354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 4: VECTOR EMBEDDINGS & KNOWLEDGE BASE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\AppData\\Local\\Temp\\ipykernel_2828\\3136432108.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector database created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 4: EMBEDDINGS AND VECTOR DATABASE\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 4: VECTOR EMBEDDINGS & KNOWLEDGE BASE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./career_chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"✅ Vector database created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7d00a4-77f6-4ad1-aebd-64465a8701cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 5: RETRIEVAL OPTIMIZATION\n",
      "============================================================\n",
      "✅ Retriever configured with MMR search (k=3, fetch_k=10, λ=0.5).\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 5: RETRIEVAL CONFIGURATION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 5: RETRIEVAL OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.5}\n",
    ")\n",
    "\n",
    "print(\"✅ Retriever configured with MMR search (k=3, fetch_k=10, λ=0.5).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b205a9c7-6fac-49dc-b042-729157e68e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 6: LLM CONNECTION VIA OLLAMA\n",
      "============================================================\n",
      "✅ LLM (phi3:mini) connected successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\AppData\\Local\\Temp\\ipykernel_2828\\191238028.py:10: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"phi3:mini\", temperature=0.2, num_thread=2)\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 6: LLM SETUP\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 6: LLM CONNECTION VIA OLLAMA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    llm = Ollama(model=\"phi3:mini\", temperature=0.2, num_thread=2)\n",
    "    print(\"✅ LLM (phi3:mini) connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to connect to Ollama: {e}\")\n",
    "    print(\"💡 Ensure Ollama is running and model 'phi3:mini' is installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ab4c59-1b2d-41c1-af7b-f7d1ed976086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 7: PROMPT ENGINEERING FOR CAREER GUIDANCE\n",
      "============================================================\n",
      "✅ Prompt template created successfully.\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 7: PROMPT ENGINEERING\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 7: PROMPT ENGINEERING FOR CAREER GUIDANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a professional career guidance assistant.\n",
    "Answer the question ONLY using information from the provided context.\n",
    "\n",
    "Rules:\n",
    "1. Do not guess — use only the career documents below.\n",
    "2. If you cannot find the answer, say:\n",
    "   \"The provided documents do not contain information to answer this question.\"\n",
    "3. Always mention which document or section your answer comes from.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "print(\"✅ Prompt template created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12632a3a-9318-4907-a7cd-1a7bec5fb7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PART 8: RAG CHAIN ASSEMBLY\n",
      "============================================================\n",
      "✅ RAG chain assembled successfully!\n",
      "   Components connected: Retriever → Prompt → LLM → Response\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 8: RAG CHAIN ASSEMBLY\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Combine retriever, prompt, and LLM\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 8: RAG CHAIN ASSEMBLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",  # Combine all retrieved chunks\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"✅ RAG chain assembled successfully!\")\n",
    "print(\"   Components connected: Retriever → Prompt → LLM → Response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff56ee2-35d0-4412-aef7-6fe56f8c905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# PART 9: ANSWER VALIDATION SYSTEM\n",
    "# ========================================================================\n",
    "\n",
    "def validate_answer(answer, source_docs):\n",
    "    hallucination_phrases = [\"i think\", \"probably\", \"seems\", \"perhaps\", \"usually\", \"generally\"]\n",
    "    confidence = 1.0\n",
    "    warnings = []\n",
    "\n",
    "    for phrase in hallucination_phrases:\n",
    "        if phrase in answer.lower():\n",
    "            confidence -= 0.2\n",
    "            warnings.append(f\"Uncertain phrase detected: '{phrase}'\")\n",
    "\n",
    "    cited = any(doc.metadata.get(\"source\", \"\").lower() in answer.lower() for doc in source_docs)\n",
    "    if not cited:\n",
    "        confidence -= 0.3\n",
    "        warnings.append(\"No source citation detected.\")\n",
    "    \n",
    "    return max(confidence, 0.0), warnings\n",
    "\n",
    "\n",
    "def ask_question_with_validation(question):\n",
    "    print(f\"\\n🤔 Question: {question}\")\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    answer = result[\"result\"]\n",
    "    sources = result[\"source_documents\"]\n",
    "    \n",
    "    conf, warns = validate_answer(answer, sources)\n",
    "    \n",
    "    print(\"\\n📝 Answer:\")\n",
    "    print(answer)\n",
    "    print(f\"\\n📊 Confidence Score: {conf:.2f}\")\n",
    "    if warns:\n",
    "        for w in warns:\n",
    "            print(\"⚠️\", w)\n",
    "    \n",
    "    print(\"\\n📚 Sources:\")\n",
    "    for s in sources:\n",
    "        print(\"-\", s.metadata.get(\"source\", \"Unknown\"))\n",
    "    \n",
    "    return result, conf, warns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52679b18-f78c-439a-946c-921193d94c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "WORKSHOP DEMONSTRATION: TESTING THE RAG SYSTEM — CAREER GUIDANCE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🤔 Testing Question: What are the key sections that should be included in a professional resume?\n",
      "================================================================================\n",
      "🧪 Running RAG pipeline...\n",
      "\n",
      "\n",
      "🤔 Question: What are the key sections that should be included in a professional resume?\n",
      "\n",
      "📝 Answer:\n",
      "According to the provided documents, particularly under \"ADDITIONAL SECTIONS,\" some of the most commonly listed additional sections after Education include Study Abroad experiences and Certifications or Licensure. Experience-related sections that stand out are Leadership roles due to their impressiveness to employers. Furthermore, involvement in Activities or Extracurricular Involvement/Student Organizations is also recommended for inclusion if applicable. Honors or Awards should be highlighted as well when relevant. Community Service and Volunteer work can add value by showcasing one's commitment beyond academics and employment. Professional Affiliations are another section that could enhance a resume, indicating membership in professional organizations related to the field of interest. These sections help create a comprehensive picture of an individual’senvironmental engagement, leadership capabilities, recognition received, community involvement, and industry connections beyond just work experience or education credentials (Document: ADDITIONAL SECTIONS).\n",
      "\n",
      "📊 Confidence Score: 0.70\n",
      "⚠️ No source citation detected.\n",
      "\n",
      "📚 Sources:\n",
      "- data(1)\\cdg_2020_final.pdf\n",
      "- data(1)\\2024–25-Career-Planning-Guide.pdf\n",
      "- data(1)\\2024–25-Career-Planning-Guide.pdf\n",
      "\n",
      "================================================================================\n",
      "✅ Finished testing question: What are the key sections that should be included in a professional resume?\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🤔 Testing Question: How can I prepare effectively for a job interview?\n",
      "================================================================================\n",
      "🧪 Running RAG pipeline...\n",
      "\n",
      "\n",
      "🤔 Question: How can I prepare effectively for a job interview?\n",
      "\n",
      "📝 Answer:\n",
      "To prepare effectively for a job interview, follow these steps from the provided documents:\n",
      "\n",
      "1. Identify what you want to get out of the meeting (Document Section on Preparing).\n",
      "2. Research the professional and his/her company as well as the industry they work in (Section on Interviewing - Document 33).\n",
      "3. Review your experiences, interests, skills, and prepare a list of questions for them based on this information (Sections from both documents: Preparing & Questions for an Informational Interview – Section 32-35).\n",
      "4. Practice introducing yourself effectively to make the best first impression during interviews (Section on Introduction - Document 40).\n",
      "5. Learn perfect delivery and conquer nerves with interactive mock interview tools, which can be found in Big Interview at nd.biginterview.com for online practice sessions that include feedback from professionals across various industries (Sections: On-Camera Presence & Practice Online - Documents).\n",
      "6. Dress appropriately and maintain good body language whether the interview is virtual or in person, as this can make a significant difference to your first impression (Section on Big Interview – Section 40).\n",
      "\n",
      "📊 Confidence Score: 0.70\n",
      "⚠️ No source citation detected.\n",
      "\n",
      "📚 Sources:\n",
      "- data(1)\\cdg_2020_final.pdf\n",
      "- data(1)\\cdg_2020_final.pdf\n",
      "- data(1)\\2024–25-Career-Planning-Guide.pdf\n",
      "\n",
      "================================================================================\n",
      "✅ Finished testing question: How can I prepare effectively for a job interview?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 10: HANDS-ON TESTING\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Test the complete RAG system (Career Guidance Domain)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORKSHOP DEMONSTRATION: TESTING THE RAG SYSTEM — CAREER GUIDANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Two realistic questions for your career-focused RAG\n",
    "questions = [\n",
    "    \"What are the key sections that should be included in a professional resume?\",\n",
    "    \"How can I prepare effectively for a job interview?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"🤔 Testing Question: {q}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"🧪 Running RAG pipeline...\\n\")\n",
    "    result, confidence, warnings = ask_question_with_validation(q)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✅ Finished testing question: {q}\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f579e-c525-4266-9c70-e2e0dbe18a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
